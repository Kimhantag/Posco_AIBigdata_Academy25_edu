{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kimhantag/Posco_AIBigdata_Academy25_edu/blob/main/5.Regularization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qq1cfKx9P4Tf"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model, layers, regularizers, initializers\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "random.seed(5)\n",
        "np.random.seed(5)\n",
        "tf.random.set_seed(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_trainval, y_trainval), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "print(type(x_trainval), x_trainval.shape)\n",
        "print(type(y_trainval), y_trainval.shape)\n",
        "\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x_trainval, y_trainval, test_size= 1/6, shuffle=True, stratify = y_trainval, random_state=34)\n",
        "print(type(x_train), x_train.shape)\n",
        "print(type(y_train), y_train.shape)\n",
        "\n",
        "num_features = x_train.shape[1] * x_train.shape[2]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuEyqpPcQFIB",
        "outputId": "053c74a5-ea20-40e5-c35a-7baf9272b1ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "<class 'numpy.ndarray'> (60000, 28, 28)\n",
            "<class 'numpy.ndarray'> (60000,)\n",
            "<class 'numpy.ndarray'> (50000, 28, 28)\n",
            "<class 'numpy.ndarray'> (50000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale to [0, 1]\n",
        "x_train, x_valid, x_test = x_train.astype('float32') / 255 , x_valid.astype('float32') / 255, x_test.astype('float32') / 255\n",
        "\n",
        "# CNN need a dimension of channels\n",
        "x_train = x_train.reshape(-1,num_features)\n",
        "x_valid = x_valid.reshape(-1, num_features)\n",
        "x_test = x_test.reshape(-1, num_features)\n",
        "\n",
        "\n",
        "print(x_train.shape, x_valid.shape, x_test.shape)\n",
        "print(y_train.shape, y_valid.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wFuYzBcRS_V",
        "outputId": "ab0c26b1-9b73-4a95-9ffb-af81b8e3e15b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 784) (10000, 784) (10000, 784)\n",
            "(50000,) (10000,) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.keras.saving.register_keras_serializable()\n",
        "class NeuralNet(Model): # Regularization skill을 추가하지 않은 기본 뉴럴네트워크 구조\n",
        "    def __init__(self):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.fc1 = layers.Dense(128, kernel_initializer = initializers.GlorotNormal())\n",
        "        self.bn1 = layers.BatchNormalization()\n",
        "        self.ac1 = layers.Activation(tf.nn.relu)\n",
        "        self.fc2 = layers.Dense(256, kernel_initializer = initializers.GlorotNormal())\n",
        "        self.bn2 = layers.BatchNormalization()\n",
        "        self.ac2 = layers.Activation(tf.nn.relu)\n",
        "        self.out = layers.Dense(10, kernel_initializer = initializers.GlorotNormal())\n",
        "\n",
        "    def call(self, x, is_training=False):\n",
        "        x = self.fc1(x)\n",
        "        x = self.bn1(x, training=is_training)\n",
        "        x = self.ac1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.bn2(x, training=is_training)\n",
        "        x = self.ac2(x)\n",
        "        x = self.out(x)\n",
        "        if not is_training:\n",
        "            x = tf.nn.softmax(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "dTRzdVW0QG3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn = NeuralNet()"
      ],
      "metadata": {
        "id": "5u3TqyFgQLar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn.compile(loss = 'sparse_categorical_crossentropy', optimizer = tf.keras.optimizers.SGD(learning_rate=0.1), metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "c9b8691zQT3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#early stopping\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=4, verbose=1)\n",
        "#model checkpoint\n",
        "#tf.keras.callbacks.ModelCheckpoing(path, monitor, mode, save_Best_only)\n",
        "mc = tf.keras.callbacks.ModelCheckpoint('./mlp', monitor='accuracy', mode='max', save_best_only=True, verbose=1)"
      ],
      "metadata": {
        "id": "w51u8Ce3Qnn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn.fit(x_train, y_train,\n",
        "                epochs=20,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_valid, y_valid),\n",
        "                callbacks = [es, mc]\n",
        "                )"
      ],
      "metadata": {
        "id": "k4s4c6YNQjyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn_result = nn.evaluate(x_test, y_test)  # 기본 성능, 앞으로 Regularization skill을 적용했을 때 이 부분의 성능과 비교해볼 것"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXht1B5oQ3uc",
        "outputId": "95e5090c-41f7-4a29-8b61-6e849b14fd48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0780 - accuracy: 0.9777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('test loss: ', nn_result[0])\n",
        "print('test acc: ', nn_result[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdZY9JSQR-va",
        "outputId": "b3ca62a3-efb1-46d9-b063-cedbe1ba731a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss:  0.07804710417985916\n",
            "test acc:  0.9776999950408936\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regularization\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### weight decay"
      ],
      "metadata": {
        "id": "0UAdQdWpSuS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WD_NeuralNet(Model):\n",
        "    def __init__(self):\n",
        "        super(WD_NeuralNet, self).__init__()\n",
        "        self.fc1 = layers.Dense(128,  kernel_initializer = initializers.GlorotNormal(), kernel_regularizer=regularizers.l2(0.01))\n",
        "        self.bn1 = layers.BatchNormalization()\n",
        "        self.ac1 = layers.Activation(tf.nn.relu)\n",
        "        self.fc2 = layers.Dense(256,  kernel_initializer = initializers.GlorotNormal(), kernel_regularizer=regularizers.l2(0.01))\n",
        "        self.bn2 = layers.BatchNormalization()\n",
        "        self.ac2 = layers.Activation(tf.nn.relu)\n",
        "        self.out = layers.Dense(10,  kernel_initializer = initializers.GlorotNormal(), kernel_regularizer=regularizers.l2(0.01))\n",
        "\n",
        "    def call(self, x, is_training=False):\n",
        "        x = self.fc1(x)\n",
        "        x = self.bn1(x, training=is_training)\n",
        "        x = self.ac1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.bn2(x, training=is_training)\n",
        "        x = self.ac2(x)\n",
        "        x = self.out(x)\n",
        "        if not is_training:\n",
        "            x = tf.nn.softmax(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "qwJARd-hSeGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn_wd = WD_NeuralNet()\n",
        "nn_wd.compile(loss = 'sparse_categorical_crossentropy', optimizer = tf.keras.optimizers.SGD(learning_rate=0.1), metrics = ['accuracy'])\n",
        "nn_wd.fit(x_train, y_train,\n",
        "                epochs=20,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_valid, y_valid),\n",
        "                callbacks = [es, mc]\n",
        "                )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdwaUA6ISzcN",
        "outputId": "3e0342a8-4f31-4572-bc01-9aefefa15341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "383/391 [============================>.] - ETA: 0s - loss: 2.9140 - accuracy: 0.8446\n",
            "Epoch 1: accuracy did not improve from 0.99578\n",
            "391/391 [==============================] - 5s 10ms/step - loss: 2.8876 - accuracy: 0.8456 - val_loss: 1.5528 - val_accuracy: 0.9022\n",
            "Epoch 2/20\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.1409 - accuracy: 0.9014\n",
            "Epoch 2: accuracy did not improve from 0.99578\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.1380 - accuracy: 0.9017 - val_loss: 0.8730 - val_accuracy: 0.9094\n",
            "Epoch 3/20\n",
            "383/391 [============================>.] - ETA: 0s - loss: 0.7755 - accuracy: 0.9099\n",
            "Epoch 3: accuracy did not improve from 0.99578\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7739 - accuracy: 0.9101 - val_loss: 0.7009 - val_accuracy: 0.9205\n",
            "Epoch 4/20\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.6713 - accuracy: 0.9132\n",
            "Epoch 4: accuracy did not improve from 0.99578\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6704 - accuracy: 0.9134 - val_loss: 0.6279 - val_accuracy: 0.9211\n",
            "Epoch 5/20\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.6201 - accuracy: 0.9192\n",
            "Epoch 5: accuracy did not improve from 0.99578\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.6197 - accuracy: 0.9192 - val_loss: 0.6039 - val_accuracy: 0.9233\n",
            "Epoch 6/20\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.5891 - accuracy: 0.9214\n",
            "Epoch 6: accuracy did not improve from 0.99578\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.5890 - accuracy: 0.9215 - val_loss: 0.5694 - val_accuracy: 0.9296\n",
            "Epoch 7/20\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.5589 - accuracy: 0.9260\n",
            "Epoch 7: accuracy did not improve from 0.99578\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.5596 - accuracy: 0.9257 - val_loss: 0.5856 - val_accuracy: 0.9092\n",
            "Epoch 8/20\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.5412 - accuracy: 0.9254\n",
            "Epoch 8: accuracy did not improve from 0.99578\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.5410 - accuracy: 0.9253 - val_loss: 0.5239 - val_accuracy: 0.9312\n",
            "Epoch 9/20\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.5204 - accuracy: 0.9282\n",
            "Epoch 9: accuracy did not improve from 0.99578\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5203 - accuracy: 0.9282 - val_loss: 0.5157 - val_accuracy: 0.9278\n",
            "Epoch 10/20\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.5017 - accuracy: 0.9283\n",
            "Epoch 10: accuracy did not improve from 0.99578\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5028 - accuracy: 0.9276 - val_loss: 0.5441 - val_accuracy: 0.9100\n",
            "Epoch 11/20\n",
            "383/391 [============================>.] - ETA: 0s - loss: 0.4939 - accuracy: 0.9270\n",
            "Epoch 11: accuracy did not improve from 0.99578\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.4941 - accuracy: 0.9270 - val_loss: 0.5255 - val_accuracy: 0.9212\n",
            "Epoch 12/20\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.4761 - accuracy: 0.9306\n",
            "Epoch 12: accuracy did not improve from 0.99578\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.4765 - accuracy: 0.9304 - val_loss: 0.5807 - val_accuracy: 0.8865\n",
            "Epoch 13/20\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.4606 - accuracy: 0.9327\n",
            "Epoch 13: accuracy did not improve from 0.99578\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.4606 - accuracy: 0.9327 - val_loss: 0.4895 - val_accuracy: 0.9232\n",
            "Epoch 14/20\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.4562 - accuracy: 0.9304\n",
            "Epoch 14: accuracy did not improve from 0.99578\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4559 - accuracy: 0.9307 - val_loss: 0.4192 - val_accuracy: 0.9446\n",
            "Epoch 15/20\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.4579 - accuracy: 0.9303\n",
            "Epoch 15: accuracy did not improve from 0.99578\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.4579 - accuracy: 0.9303 - val_loss: 0.4524 - val_accuracy: 0.9318\n",
            "Epoch 16/20\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.4448 - accuracy: 0.9323\n",
            "Epoch 16: accuracy did not improve from 0.99578\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.4443 - accuracy: 0.9325 - val_loss: 0.4253 - val_accuracy: 0.9425\n",
            "Epoch 17/20\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.4372 - accuracy: 0.9331\n",
            "Epoch 17: accuracy did not improve from 0.99578\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4371 - accuracy: 0.9332 - val_loss: 0.4183 - val_accuracy: 0.9437\n",
            "Epoch 18/20\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.4383 - accuracy: 0.9324\n",
            "Epoch 18: accuracy did not improve from 0.99578\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.4387 - accuracy: 0.9322 - val_loss: 0.8030 - val_accuracy: 0.7993\n",
            "Epoch 19/20\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.4665 - accuracy: 0.9241\n",
            "Epoch 19: accuracy did not improve from 0.99578\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4665 - accuracy: 0.9241 - val_loss: 0.4659 - val_accuracy: 0.9317\n",
            "Epoch 20/20\n",
            "383/391 [============================>.] - ETA: 0s - loss: 0.4419 - accuracy: 0.9311\n",
            "Epoch 20: accuracy did not improve from 0.99578\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4404 - accuracy: 0.9315 - val_loss: 0.4173 - val_accuracy: 0.9381\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e60d40bd4b0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn_wd_result = nn_wd.evaluate(x_test, y_test)\n",
        "print('test loss: ', nn_wd_result[0])\n",
        "print('test acc: ', nn_wd_result[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-53YvFRTRbd",
        "outputId": "856fb434-8e14-4a8c-8a3e-45a94363ce14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.4048 - accuracy: 0.9394\n",
            "test loss:  0.4048057794570923\n",
            "test acc:  0.9394000172615051\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DO_NeuralNet(Model):\n",
        "    def __init__(self):\n",
        "        super(DO_NeuralNet, self).__init__()\n",
        "        self.fc1 = layers.Dense(128, kernel_initializer = initializers.GlorotNormal())\n",
        "        self.bn1 = layers.BatchNormalization()\n",
        "        self.ac1 = layers.Activation(tf.nn.relu)\n",
        "        self.do1 = layers.Dropout(rate=0.5)\n",
        "        self.fc2 = layers.Dense(256, kernel_initializer = initializers.GlorotNormal())\n",
        "        self.bn2 = layers.BatchNormalization()\n",
        "        self.ac2 = layers.Activation(tf.nn.relu)\n",
        "        self.do2 = layers.Dropout(rate=0.5)\n",
        "        self.out = layers.Dense(num_classes, kernel_initializer = initializers.GlorotNormal())\n",
        "\n",
        "    def call(self, x, is_training=False):\n",
        "        x = self.fc1(x)\n",
        "        x = self.bn1(x, training=is_training)\n",
        "        x = self.ac1(x)\n",
        "        x = self.do1(x, training=is_training)\n",
        "        x = self.fc2(x)\n",
        "        x = self.bn2(x, training=is_training)\n",
        "        x = self.ac2(x)\n",
        "        x = self.do2(x, training=is_training)\n",
        "        x = self.out(x)\n",
        "        if not is_training:\n",
        "            x = tf.nn.softmax(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "yCCwW9llTkZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn_do = DO_NeuralNet()\n",
        "nn_do.compile(loss = 'sparse_categorical_crossentropy', optimizer = tf.keras.optimizers.SGD(learning_rate=0.1), metrics = ['accuracy'])\n",
        "nn_do.fit(x_train, y_train,\n",
        "                epochs=20,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_valid, y_valid),\n",
        "                callbacks = [es, mc]\n",
        "                )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ic7L--ZnUnid",
        "outputId": "3d99206b-a34e-487d-a4c9-ba584f25fb41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.4939 - accuracy: 0.8605\n",
            "Epoch 1: accuracy did not improve from 0.99578\n",
            "391/391 [==============================] - 5s 9ms/step - loss: 0.4933 - accuracy: 0.8607 - val_loss: 0.2747 - val_accuracy: 0.9209\n",
            "Epoch 2/20\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.2291 - accuracy: 0.9322\n",
            "Epoch 2: accuracy did not improve from 0.99578\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.2284 - accuracy: 0.9324 - val_loss: 0.2035 - val_accuracy: 0.9403\n",
            "Epoch 3/20\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.1723 - accuracy: 0.9494\n",
            "Epoch 3: accuracy did not improve from 0.99578\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.1718 - accuracy: 0.9496 - val_loss: 0.1659 - val_accuracy: 0.9507\n",
            "Epoch 4/20\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.1384 - accuracy: 0.9594\n",
            "Epoch 4: accuracy did not improve from 0.99578\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.1382 - accuracy: 0.9595 - val_loss: 0.1400 - val_accuracy: 0.9582\n",
            "Epoch 5/20\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.1133 - accuracy: 0.9675\n",
            "Epoch 5: accuracy did not improve from 0.99578\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.1132 - accuracy: 0.9676 - val_loss: 0.1341 - val_accuracy: 0.9598\n",
            "Epoch 6/20\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.0966 - accuracy: 0.9714\n",
            "Epoch 6: accuracy did not improve from 0.99578\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.0964 - accuracy: 0.9714 - val_loss: 0.1214 - val_accuracy: 0.9638\n",
            "Epoch 7/20\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.0823 - accuracy: 0.9759\n",
            "Epoch 7: accuracy did not improve from 0.99578\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.0824 - accuracy: 0.9759 - val_loss: 0.1165 - val_accuracy: 0.9655\n",
            "Epoch 8/20\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.0723 - accuracy: 0.9788\n",
            "Epoch 8: accuracy did not improve from 0.99578\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.0722 - accuracy: 0.9788 - val_loss: 0.1109 - val_accuracy: 0.9658\n",
            "Epoch 9/20\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.0639 - accuracy: 0.9815\n",
            "Epoch 9: accuracy did not improve from 0.99578\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.0639 - accuracy: 0.9814 - val_loss: 0.1000 - val_accuracy: 0.9695\n",
            "Epoch 10/20\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.0564 - accuracy: 0.9832\n",
            "Epoch 10: accuracy did not improve from 0.99578\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.0564 - accuracy: 0.9832 - val_loss: 0.0983 - val_accuracy: 0.9706\n",
            "Epoch 11/20\n",
            "383/391 [============================>.] - ETA: 0s - loss: 0.0492 - accuracy: 0.9854\n",
            "Epoch 11: accuracy did not improve from 0.99578\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.0498 - accuracy: 0.9852 - val_loss: 0.1104 - val_accuracy: 0.9656\n",
            "Epoch 12/20\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.0447 - accuracy: 0.9869\n",
            "Epoch 12: accuracy did not improve from 0.99578\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.0447 - accuracy: 0.9869 - val_loss: 0.0869 - val_accuracy: 0.9740\n",
            "Epoch 13/20\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.0392 - accuracy: 0.9888\n",
            "Epoch 13: accuracy did not improve from 0.99578\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.0391 - accuracy: 0.9888 - val_loss: 0.1047 - val_accuracy: 0.9676\n",
            "Epoch 14/20\n",
            "382/391 [============================>.] - ETA: 0s - loss: 0.0343 - accuracy: 0.9906\n",
            "Epoch 14: accuracy did not improve from 0.99578\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.0341 - accuracy: 0.9906 - val_loss: 0.0881 - val_accuracy: 0.9738\n",
            "Epoch 15/20\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.0310 - accuracy: 0.9915\n",
            "Epoch 15: accuracy did not improve from 0.99578\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0309 - accuracy: 0.9915 - val_loss: 0.0925 - val_accuracy: 0.9735\n",
            "Epoch 16/20\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.0274 - accuracy: 0.9926\n",
            "Epoch 16: accuracy did not improve from 0.99578\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.0273 - accuracy: 0.9925 - val_loss: 0.0877 - val_accuracy: 0.9752\n",
            "Epoch 16: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a1e2a707640>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn_do_result = nn_do.evaluate(x_test, y_test)\n",
        "print('test loss: ', nn_do_result[0])\n",
        "print('test acc: ', nn_do_result[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67BEyTTRUXg-",
        "outputId": "1f3a5663-6fd5-41f0-a632-c5bca9d0ee2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0827 - accuracy: 0.9774\n",
            "test loss:  0.08274487406015396\n",
            "test acc:  0.977400004863739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model_Ensemble"
      ],
      "metadata": {
        "id": "lZrEUjWmVENZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_pred, y_true):\n",
        "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n",
        "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32)).numpy()\n",
        "\n",
        "pred = (nn.predict(x_test)+ nn_wd.predict(x_test) + nn_do.predict(x_test))/3\n",
        "\n",
        "ensemble_result = accuracy(pred, y_test)\n",
        "\n",
        "print(ensemble_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L70bROvQUu0q",
        "outputId": "783454bc-1835-409a-ab4a-63ec1f4508c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "0.9792\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 최종 결과 종합 비교  ##어떤 스킬이 주로 성능향상 효과를 보이는 경향이 있다고 해도 항상 동일하게 그 성능 향상 효과를 관측하기는 어려울 수 있음\n",
        "print(ensemble_result)  # ensemble 정확도\n",
        "print(nn_result[1])  # 기본 뉴럴네트워크의 정확도\n",
        "print(nn_wd_result[1])  # 기본 뉴럴네트워크에 weight decay 적용한 정확도\n",
        "print(nn_do_result[1])   # 기본 뉴럴네트워크에 dropout 적용한 정확도\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08Thw9tvVvp6",
        "outputId": "67b69b56-67c5-4a7c-a086-6baf6b606879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9792\n",
            "0.9776999950408936\n",
            "0.9394000172615051\n",
            "0.977400004863739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cJje2pneXu49"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
